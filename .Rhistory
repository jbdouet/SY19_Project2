x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
a <- 20
EM(x,mu_init,sigma_init,pi_init,a)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
print(Q_Value)
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
mu <- mu_update
sigma <- sigma_update
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
#if (err<0.00001){
#  print(it)
#  return(theta)
#}
it = it+1
}
}
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
print(Q_Value)
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
a <- 20
EM(x,mu_init,sigma_init,pi_init,a)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
print(Q_Value)
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
a <- 20
EM(x,mu_init,sigma_init,pi_init,a)
a <- 20
mu <- 0
sigma <- 1
pi <- 0.4 # proportion de la loi normale dans le mélange
n <- 100
tirage <- sample(c(0,1), n, replace = TRUE, prob = c(pi,1-pi))
phi_sample <- rnorm(n, mean = mu , sd = sigma)
unif_sample <- runif(n, min = -a, max = a)
final_sample <- tirage*phi_sample + (1-tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
EM(x,mu_init,sigma_init,pi_init,a)
a <- 20
mu <- 0
sigma <- 1
pi <- 0.9 # proportion de la loi normale dans le mélange
n <- 100
tirage <- sample(c(0,1), n, replace = TRUE, prob = c(pi,1-pi))
phi_sample <- rnorm(n, mean = mu , sd = sigma)
unif_sample <- runif(n, min = -a, max = a)
final_sample <- tirage*phi_sample + (1-tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
EM(x,mu_init,sigma_init,pi_init,a)
final_sample <- (1-tirage)*phi_sample + (tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
EM(x,mu_init,sigma_init,pi_init,a)
data_expressions <- read.csv("data/expressions_train.txt",sep = " ")
X_expressions <- data_expressions[,1:4200]
y_expressions <-data_expressions$y
table(y_expressions)
setwd("~/Documents/GI05/SY19/TPs/TP6/SY19_Project2")
library(caret)
set.seed(101)
data_expressions <- read.csv("data/expressions_train.txt",sep = " ")
X_expressions <- data_expressions[,1:4200]
y_expressions <-data_expressions$y
table(y_expressions)
I<-matrix(as.matrix(X_expressions[14,]),60,70)
I1 <- apply(I, 1, rev)
image(t(I1),col=gray(0:255 / 255))
dim(X_expressions)
dim(X_expressions[complete.cases(X_expressions), ])
dim(na.omit(X_expressions))
tst <-na.omit(unname(X_expressions))
n=nrow(data_expressions)
ntrain=ceiling(n*2/3)
ntst=n-ntrain
train<-sample(1:n,ntrain)
data_expressions.test<-data_expressions[-train,]
data_expressions.train<-data_expressions[train,]
X_preprocessed <- X_expressions[, !apply(X_expressions == 0, 2, all)]
data_preprocessed <- data_expressions[, !apply(data_expressions == 0, 2, all)]
I14<-matrix(as.matrix(X_expressions[14,]),60,70)
I14_eyes<-matrix(as.matrix(I14[301:1260]),nrow = 60,ncol = 16)
Ieyes <- apply(I14_eyes, 1, rev)
image(t(Ieyes),col=gray(0:255 / 255))
I14<-matrix(as.matrix(X_expressions[14,]),60,70)
I14_mouth<-matrix(as.matrix(I14[2460:3359]),nrow = 60,ncol = 15)
Imouth <- apply(I14_mouth, 1, rev)
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
image(t(I1),col=gray(0:255 / 255))
require(graphics)
prin_comp <- prcomp(X_selproc)
std_dev <- prin_comp$sdev
pr_var <- std_dev^2
require(graphics)
prin_comp <- prcomp(X_selproc)
std_dev <- prin_comp$sdev
pr_var <- std_dev^2
pr_var[1:10]
prop_varex <- pr_var/sum(pr_var)
data_selproc=data.frame(X_selproc,y=y_expressions)
require(graphics)
prin_comp <- prcomp(X_selproc)
std_dev <- prin_comp$sdev
require(graphics)
prin_comp <- prcomp(X_selproc)
X_selproc<- Xselected[, !apply(Xselected == 0, 2, all)]
data_selproc=data.frame(X_selproc,y=y_expressions)
Xselected <- cbind(X_expressions[301:1260],X_expressions[2601:3260])
X_selproc<- Xselected[, !apply(Xselected == 0, 2, all)]
data_selproc=data.frame(X_selproc,y=y_expressions)
require(graphics)
prin_comp <- prcomp(X_selproc)
std_dev <- prin_comp$sdev
pr_var <- std_dev^2
pr_var[1:10]
prop_varex <- pr_var/sum(pr_var)
plot(prop_varex, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
plot(cumsum(prop_varex), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
require(graphics)
par(mfrow = c(1, 2))
plot(prop_varex, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
plot(cumsum(prop_varex), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
require(graphics)
par(mfrow = c(1, 2))
plot(prop_varex, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
plot(cumsum(prop_varex), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
library(keras)
use_backend(backend = "tensorflow")
use_condaenv("r-tensorflow",required = TRUE )
img_rows <- 60
img_cols <- 70
X_train <- data_expressions.train[,1:4200]
X_test <- data_expressions.test[,1:4200]
y_train <-  data_expressions.train$y
y_test <-  data_expressions.test$y
X_train1<- array_reshape(unname(X_train), dim=c(dim(X_train)[1], dim(X_train)[2]))
X_test1<- array_reshape(unname(X_test), dim=c(dim(X_test)[1], dim(X_test)[2]))
X_train1 <- X_train / 255
X_test1 <- X_test / 255
X_train2 <- array_reshape(unname(X_train), c(nrow(X_train), img_rows, img_cols, 1))
X_test2 <- array_reshape(unname(X_test), c(nrow(X_test), img_rows, img_cols, 1))
input_shape <- c(img_rows, img_cols, 1)
y_train_cat <- to_categorical(y_train)
y_test_cat <- to_categorical(y_test)
y_train_cat2 <- y_train_cat[,2:7]
y_test_cat2 <- y_test_cat[,2:7]
num_classes=6
model <- keras_model_sequential()
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
summary(model)
opt <- optimizer_rmsprop(lr = 0.0001, decay = 1e-6)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = opt,
metrics = c('accuracy')
)
history <- model %>% fit(
X_train2, y_train_cat2,
epochs = 10, batch_size = 1,
validation_split = 0.2
)
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 12, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 14, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 6, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
128
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 12, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 14, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 12, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
num_classes=6
model <- keras_model_sequential()
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 32, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 64, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
model <- keras_model_sequential()
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 12, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 12, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
model <- keras_model_sequential()
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 12, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 12, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 6, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
summary(model)
opt <- optimizer_rmsprop(lr = 0.0001, decay = 1e-6)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = opt,
metrics = c('accuracy')
)
history <- model %>% fit(
X_train2, y_train_cat2,
epochs = 10, batch_size = 1,
validation_split = 0.2
)
model <- keras_model_sequential()
model %>%
#layer_dense(units = 10, activation = 'relu', input_shape = c(4200)) %>%
layer_conv_2d(filters = 12, kernel_size = c(3,3), activation = 'relu',
input_shape = input_shape) %>%
layer_conv_2d(filters = 24, kernel_size = c(3,3), activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2, 2)) %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 6, activation = 'relu') %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = num_classes, activation = 'softmax')
summary(model)
opt <- optimizer_rmsprop(lr = 0.0001, decay = 1e-6)
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = opt,
metrics = c('accuracy')
)
history <- model %>% fit(
X_train2, y_train_cat2,
epochs = 10, batch_size = 1,
validation_split = 0.2
)
plot(history)
I14<-matrix(as.matrix(X_expressions[14,]),60,70)
I14_eyes<-matrix(as.matrix(I14[301:1260]),nrow = 60,ncol = 16)
Ieyes <- apply(I14_eyes, 1, rev)
image(t(Ieyes),col=gray(0:255 / 255))
I14<-matrix(as.matrix(X_expressions[14,]),60,70)
I14_mouth<-matrix(as.matrix(I14[2460:3359]),nrow = 60,ncol = 15)
Imouth <- apply(I14_mouth, 1, rev)
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
save.image("~/Documents/GI05/SY19/TPs/TP6/SY19_Project2/envJB.RData")
```{r, echo=F,fig.height=2, fig.width=5}
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
