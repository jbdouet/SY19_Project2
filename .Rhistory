repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
print(Q_Value)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
mu <- mu_update
sigma <- sigma_update
pi <- pi_update
theta<-c(mu, sigma, pi)
tvec = c(tmu, tsigma,tpi)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.01){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0
pi_init <- 1
a <- 2
EM(x,mu_init,sigma_init,pi_init,a)
Q(x,mu_init,sigma_init,pi_init,a)
pi_init <- 0.5
a <- 2
EM(x,mu_init,sigma_init,pi_init,a)
Q(x,mu_init,sigma_init,pi_init,a)
pi_init <- 0.7
a <- 2
Q(x,mu_init,sigma_init,pi_init,a)
mu_init <- 0
sigma_init <- 0
pi_init <- 0.7
Q(x,mu_init,sigma_init,pi_init,a)
pi_init <- 0.7
Q(x,mu_init,sigma_init,pi_init,a)
pi_init <- 0.2
Q(x,mu_init,sigma_init,pi_init,a)
EM(x,mu_init,sigma_init,pi_init,a)
a <- 20
Q(x,mu_init,sigma_init,pi_init,a)
Q(x,mu_init,sigma_init,pi_init,a)
Q <- function (x,mu,sigma,pi,a){
phi <-dnorm(x, mean = mu, sd = sigma, log = FALSE)
print (phi)
res <- (pi * phi)/ (phi*pi + (1-pi)*1/(2*a))
return(res)
}
Q(x,mu_init,sigma_init,pi_init,a)
x
x<- final_sample
sigma_init <- 0.1
pi_init <- 0.2
Q(x,mu_init,sigma_init,pi_init,a)
EM(x,mu_init,sigma_init,pi_init,a)
Q <- function (x,mu,sigma,pi,a){
phi <-dnorm(x, mean = mu, sd = sigma, log = FALSE)
res <- (pi * phi)/ (phi*pi + (1-pi)*1/(2*a))
return(res)
}
Q_Value <- Q (x,mu,sigma,pi,a)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
mu <- mu_update
sigma <- sigma_update
pi <- pi_update
theta<-c(mu, sigma, pi)
tvec = c(tmu, tsigma,tpi)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
a <- 20
EM(x,mu_init,sigma_init,pi_init,a)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
print(Q_Value)
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
mu <- mu_update
sigma <- sigma_update
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
#if (err<0.00001){
#  print(it)
#  return(theta)
#}
it = it+1
}
}
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
print(Q_Value)
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
a <- 20
EM(x,mu_init,sigma_init,pi_init,a)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
print(Q_Value)
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
a <- 20
EM(x,mu_init,sigma_init,pi_init,a)
a <- 20
mu <- 0
sigma <- 1
pi <- 0.4 # proportion de la loi normale dans le mélange
n <- 100
tirage <- sample(c(0,1), n, replace = TRUE, prob = c(pi,1-pi))
phi_sample <- rnorm(n, mean = mu , sd = sigma)
unif_sample <- runif(n, min = -a, max = a)
final_sample <- tirage*phi_sample + (1-tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
EM(x,mu_init,sigma_init,pi_init,a)
a <- 20
mu <- 0
sigma <- 1
pi <- 0.9 # proportion de la loi normale dans le mélange
n <- 100
tirage <- sample(c(0,1), n, replace = TRUE, prob = c(pi,1-pi))
phi_sample <- rnorm(n, mean = mu , sd = sigma)
unif_sample <- runif(n, min = -a, max = a)
final_sample <- tirage*phi_sample + (1-tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
EM(x,mu_init,sigma_init,pi_init,a)
final_sample <- (1-tirage)*phi_sample + (tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
EM(x,mu_init,sigma_init,pi_init,a)
knitr::opts_chunk$set(echo = TRUE)
load("/Users/Jean-Baptiste/Documents/GI05/SY19/TPs/TP6/SY19_Project2/envlouis.RData")
load("/Users/Jean-Baptiste/Documents/GI05/SY19/TPs/TP6/SY19_Project2/envJB.RData")
library(caret)
library(car)
library("e1071")
library(randomForest)
library(kernlab)
library(stats)
library(MASS)
options(Encoding="UTF-8")
plot(history)
load("env.Rdata",.GlobalEnv)
setwd("~/Documents/GI05/SY19/TPs/TP6/SY19_Project2")
load("env.Rdata",.GlobalEnv)
X <- dataset[,1:4200]
load("env.Rdata",.GlobalEnv)
load("envJB.Rdata",.GlobalEnv)
data_expressions <- read.csv("data/expressions_train.txt",sep = " ")
X_expressions <- data_expressions[,1:4200]
y_expressions <-data_expressions$y
table(y_expressions)
I<-matrix(as.matrix(X_expressions[14,]),60,70)
I1 <- apply(I, 1, rev)
image(t(I1),col=gray(0:255 / 255))
dim(X_expressions)
dim(X_expressions[complete.cases(X_expressions), ])
dim(na.omit(X_expressions))
tst <-na.omit(unname(X_expressions))
n=nrow(data_expressions)
ntrain=ceiling(n*2/3)
ntst=n-ntrain
train<-sample(1:n,ntrain)
data_expressions.test<-data_expressions[-train,]
data_expressions.train<-data_expressions[train,]
X_preprocessed <- X_expressions[, !apply(X_expressions == 0, 2, all)]
data_preprocessed <- data_expressions[, !apply(data_expressions == 0, 2, all)]
I14<-matrix(as.matrix(X_expressions[14,]),60,70)
I14_eyes<-matrix(as.matrix(I14[301:1260]),nrow = 60,ncol = 16)
Ieyes <- apply(I14_eyes, 1, rev)
image(t(Ieyes),col=gray(0:255 / 255))
I14<-matrix(as.matrix(X_expressions[14,]),60,70)
I14_mouth<-matrix(as.matrix(I14[2460:3359]),nrow = 60,ncol = 15)
Imouth <- apply(I14_mouth, 1, rev)
image(t(Imouth),col=gray(0:255 / 255))
par(mfrow = c(1, 2))
image(t(Ieyes),col=gray(0:255 / 255))
image(t(Imouth),col=gray(0:255 / 255))
Xselected <- cbind(X_expressions[301:1260],X_expressions[2460:3359])
X_selproc<- Xselected[, !apply(Xselected == 0, 2, all)]
data_selproc=data.frame(X_selproc,y=y_expressions)
require(graphics)
prin_comp <- prcomp(X_preprocessed)
std_dev <- prin_comp$sdev
pr_var <- std_dev^2
pr_var[1:10]
prop_varex <- pr_var/sum(pr_var)
plot(prop_varex, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
plot(cumsum(prop_varex), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
new_data <-  data.frame( prin_comp$x[,1:25],y=y_expressions)
prin_comp_pca <- prcomp(X_selproc)
std_dev2 <- prin_comp_pca$sdev
pr_var2 <- std_dev2^2
pr_var2[1:10]
prop_varex2 <- pr_var2/sum(pr_var2)
plot(prop_varex2, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
type = "b")
plot(cumsum(prop_varex2), xlab = "Principal Component",
ylab = "Cumulative Proportion of Variance Explained",
type = "b")
new_data2 <-  data.frame( prin_comp_pca$x[,1:25],y=y_expressions)
pred <- predict(prin_comp_pca, X_selproc[1:50,])
dim(pred)
test <- data.frame( pred[,1:25],y=y_expressions[1:50])
dim(test)
data_to_use <- new_data2
data_to_use <- new_data2
classifieur_expressions <-  caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
data_to_use <- new_data2
classifieur_expressions <-  caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
classifieur_expressions <-  caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
classifieur_expressions <-caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=(
method = "cv",
number =10,
verboseIter = TRUE))
trainControl
data_to_use <- new_data2
classifieur_expressions <-caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = n)) # !!! le ntrain doit correspondre à la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le même nombre d'éléments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy1 <- data_to_use[-test_i, ]
ytrain <- train_xy1$y
test_xy1 <- data_to_use[test_i, ]
ytest <- test_xy1$y
print(k)
prin_comp <- prcomp(train_xy1[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy1[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
data_to_use <- new_data2
classifieur_expressions <-caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=caret::trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = n)) # !!! le ntrain doit correspondre à la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le même nombre d'éléments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy1 <- data_to_use[-test_i, ]
ytrain <- train_xy1$y
test_xy1 <- data_to_use[test_i, ]
ytest <- test_xy1$y
print(k)
prin_comp <- prcomp(train_xy1[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy1[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
dim(test_xy1)
test_xy <- predict(prin_comp_pca,test_xy1)
predictions_rda<-predict.train(object=classifieur_expressions,test_xy)
predictions_rda
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy1$y)
cf_rda$overall["Accuracy"]
save.image("~/Documents/GI05/SY19/TPs/TP6/SY19_Project2/env.RData")
load("env.Rdata",.GlobalEnv)
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = n)) # !!! le ntrain doit correspondre à la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le même nombre d'éléments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy1 <- data_to_use[-test_i, ]
ytrain <- train_xy1$y
test_xy1 <- data_to_use[test_i, ]
ytest <- test_xy1$y
print(k)
prin_comp <- prcomp(train_xy1[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy1[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
test_xy <- predict(prin_comp_pca,test_xy1)
predictions_rda<-predict.train(object=classifieur_expressions,test_xy)
predictions_rda
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy1$y)
cf_rda$overall["Accuracy"]
