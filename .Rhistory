tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
a <- 20
EM(x,mu_init,sigma_init,pi_init,a)
a <- 20
mu <- 0
sigma <- 1
pi <- 0.4 # proportion de la loi normale dans le mélange
n <- 100
tirage <- sample(c(0,1), n, replace = TRUE, prob = c(pi,1-pi))
phi_sample <- rnorm(n, mean = mu , sd = sigma)
unif_sample <- runif(n, min = -a, max = a)
final_sample <- tirage*phi_sample + (1-tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
EM(x,mu_init,sigma_init,pi_init,a)
a <- 20
mu <- 0
sigma <- 1
pi <- 0.9 # proportion de la loi normale dans le mélange
n <- 100
tirage <- sample(c(0,1), n, replace = TRUE, prob = c(pi,1-pi))
phi_sample <- rnorm(n, mean = mu , sd = sigma)
unif_sample <- runif(n, min = -a, max = a)
final_sample <- tirage*phi_sample + (1-tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
pi_init <- 0.2
EM(x,mu_init,sigma_init,pi_init,a)
final_sample <- (1-tirage)*phi_sample + (tirage)* unif_sample
boxplot(final_sample)
EM <- function(x,mu,sigma,pi,a){
it =0
repeat{
Q_Value <- Q (x,mu,sigma,pi,a)
pi_update <- mean(Q_Value)
mu_update <- sum(Q_Value*x)/sum(Q_Value)
sigma_update <- sqrt(sum((Q_Value*(x-mu_update)^2)/sum(Q_Value)))
tmu <- abs(mu_update-mu)/mu
tpi <- abs(pi_update-pi)/pi
tsigma <- abs((sigma_update-sigma)/sigma)
err <- (pi_update-pi)^2+(sigma_update-sigma)^2+(pi_update-pi)^2
mu <- mu_update
sigma <- sigma_update
print (pi)
pi <- pi_update
theta<-c(mu, sigma, pi)
print(theta)
tvec = c(tmu, tsigma,tpi)
#if (tmu <0.001 && tpi <0.001 && tsigma < 0.001){
if (err<0.00001){
print(it)
return(theta)
}
it = it+1
}
}
x<- final_sample
mu_init <- 0
sigma_init <- 0.1
EM(x,mu_init,sigma_init,pi_init,a)
knitr::opts_chunk$set(echo = TRUE)
load("/Users/Jean-Baptiste/Documents/GI05/SY19/TPs/TP6/SY19_Project2/envlouis.RData")
load("/Users/Jean-Baptiste/Documents/GI05/SY19/TPs/TP6/SY19_Project2/envJB.RData")
library(caret)
library(car)
library("e1071")
library(randomForest)
library(kernlab)
library(stats)
library(MASS)
options(Encoding="UTF-8")
plot(history)
load("env.Rdata",.GlobalEnv)
setwd("~/Documents/GI05/SY19/TPs/TP6/SY19_Project2")
library(caret)
set.seed(101)
load("env.Rdata",.GlobalEnv)
load("envJB.Rdata",.GlobalEnv)
prin_comp2 <- prcomp(X_selproc)
std_dev2 <- prin_comp2$sdev
pr_var2 <- std_dev2^2
pr_var2[1:10]
prop_varex2 <- pr_var2/sum(pr_var2)
pred <- predict(prin_comp2, X_selproc[1:50,])
dim(pred)
test <- data.frame( pred[,1:25],y=y_expressions[1:50])
dim(test)
predictions_rda<-predict.train(object=classifieur_expressions,test[,1:25])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=data_to_use$y)
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test$y)
cf_rda$overall["Accuracy"]
cf_rda
length(predictions_rda)
length(new_data$y[1:25])
predictions_rda<-predict.train(object=classifieur_expressions,test[,1:25])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test$y)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
test_xy <- data_to_use[test_i, ]
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=train_xy$y)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=train_xy$y)
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
test_xy <- data_to_use[test_i, ]
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=train_xy$y)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[1:25],y=train_xy$y)
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
folds_i <- sample(rep(1:n_folds, length.out = n)) # !!! le ntrain doit correspondre à la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le même nombre d'éléments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
test_xy <- data_to_use[test_i, ]
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=train_xy$y)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=train_xy$y)
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
dim(test)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_preprocessed
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = n)) # !!! le ntrain doit correspondre à la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le même nombre d'éléments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
data_to_use <- data_preprocessed
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_preprocessed
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = n)) # !!! le ntrain doit correspondre à la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le même nombre d'éléments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
prin_comp_pca <- prcomp(X_selproc)
data_to_use <- new_data2
classifieur_expressions <-  caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=classifieur_expressions,test_xy)
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
cf_rda$overall["Accuracy"]
cf_rda
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = n)) # !!! le ntrain doit correspondre à la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le même nombre d'éléments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
dim(test_xy)
predictions_rda<-predict.train(object=classifieur_expressions,test_xy)
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
cf_rda$overall["Accuracy"]
predictions_rda
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy1 <- data_to_use[-test_i, ]
ytrain <- train_xy$y
test_xy1 <- data_to_use[test_i, ]
ytest <- test_xy$y
print(k)
prin_comp <- prcomp(train_xy1[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy1[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
data_to_use <- data_selproc
ncol <- ncol(data_to_use)
test_i <- which(folds_i == k)
train_xy1 <- data_to_use[-test_i, ]
ytrain <- train_xy1$y
test_xy1 <- data_to_use[test_i, ]
ytest <- test_xy1$y
print(k)
prin_comp <- prcomp(train_xy1[,1:ncol-1])
train_xy<-data.frame( prin_comp$x[,1:25],y=ytrain)
pred <- predict(prin_comp, test_xy1[,1:ncol-1])
test_xy <-data.frame( pred[,1:25],y=ytest)
npca =25
ncol= npca+1
model_rda <- caret::train(train_xy[,1:ncol-1],train_xy$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_rda<-predict.train(object=model_rda,test_xy[,1:ncol-1])
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
CV[k]<- cf_rda$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror # 0.74
data_to_use <- new_data2
classifieur_expressions <-  caret::train(data_to_use[,1:ncol-1],data_to_use$y,method='rda',trControl=trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
dim(test_xy1)
test_xy <- predict(prin_comp_pca,test_xy1)
predictions_rda<-predict.train(object=classifieur_expressions,test_xy)
predictions_rda
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
cf_rda$overall["Accuracy"]
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy$y)
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=y_test)
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy1$y)
cf_rda$overall["Accuracy"]
cf_rda
test_xy <- predict(prin_comp_pca,test_xy1)
predictions_rda<-predict.train(object=classifieur_expressions,test_xy)
predictions_rda
cf_rda<-caret::confusionMatrix(data= predictions_rda,reference=test_xy1$y)
cf_rda$overall["Accuracy"]
cf_rda
