{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tpot \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_expressions = pd.read_csv(\"data/expressions_train.txt\", sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.head of       X1   X2   X3   X4   X5   X6   X7   X8   X9  X10    ...     X4192  X4193  \\\n",
       "32    94  102  111  117  127  136  137  141  146  153    ...         0      0   \n",
       "56    73   88  101  114  138  153  161  175  181  177    ...         0      0   \n",
       "17   125  140  147  148  150  153  154  151  142  142    ...         0      0   \n",
       "147   25   77   98  125  144  152  159  169  170  178    ...         0      0   \n",
       "140   25   34   45   50   75   98  127  156  165  170    ...         0      0   \n",
       "188   20   25   50   81   91  109  120  125  144  145    ...         0      0   \n",
       "132   34   29   34   43   29   22   78  131  156  132    ...         0      0   \n",
       "20   143  148  155  161  169  176  180  186  187  184    ...         0      0   \n",
       "28    53   89   98  116  136  153  159  166  176  173    ...         0      0   \n",
       "155    8   22   79   84   87  106  117  150  171  169    ...         0      0   \n",
       "46    45   47   50   58   89  124  149  149  149  149    ...         0      0   \n",
       "100   79  107  115  129  136  139  142  143  163  172    ...         0      0   \n",
       "10    29   43   47   60   83  110  125  148  166  166    ...         0      0   \n",
       "29    22   34   50   60   73   83  108  132  152  173    ...         0      0   \n",
       "14    83  109  143  165  165  168  172  177  183  186    ...         0      0   \n",
       "174   79   83   86   86   98  122  147  163  172  180    ...         0      0   \n",
       "82    83  102  117  136  146  154  168  173  174  172    ...         0      0   \n",
       "75   127  137  141  143  143  148  148  159  168  173    ...         0      0   \n",
       "88     8   20  100  146  162  165  153  146  171  184    ...         0      0   \n",
       "178  140  144  148  153  151  153  159  172  182  182    ...         0      0   \n",
       "69    94  108  114  122  124  132  136  148  159  166    ...         0      0   \n",
       "66    29   34   47   55   60   89  130  146  149  153    ...         0      0   \n",
       "127   62   83   98  117  125  136  143  147  149  149    ...         0      0   \n",
       "157    8    8    8    8   15   29   69   86  103  123    ...         0      0   \n",
       "97    45   47   50   62   79  100  142  157  157  157    ...         0      0   \n",
       "109    8    8    8    8    8   43   55   77   86  108    ...         0      0   \n",
       "152   20   25   25   20   39   69   79   80   78   82    ...         0      0   \n",
       "78    22   73   97  121  135  146  160  174  179  186    ...         0      0   \n",
       "204   50   83   95  117  139  153  163  166  156  172    ...         0      0   \n",
       "59    47   60   39   20   20   29   29   15    8   15    ...         0      0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...       ...    ...   \n",
       "67    67   97  118  141  160  171  171  171  171  171    ...         0      0   \n",
       "5     82   86  108  129  139  135  121  114  113  110    ...         0      0   \n",
       "165   79   86   93  107  117  133  145  163  170  177    ...         0      0   \n",
       "63    47   75   89  101  104  112  119  131  139  139    ...         0      0   \n",
       "87     8    8   34   73  108  115  125  135  142  150    ...         0      0   \n",
       "104   88   98  108  135  150  176  191  200  210  216    ...         0      0   \n",
       "89    77   85   97  115  130  140  147  149  155  155    ...         0      0   \n",
       "103   39   67   89  100  111  117  133  146  150  159    ...         0      0   \n",
       "131   43   83   95  113  132  143  153  159  168  175    ...         0      0   \n",
       "149   86  105  117  139  147  159  170  178  183  185    ...         0      0   \n",
       "72    83   98  110  124  127  150  157  160  169  170    ...         0      0   \n",
       "211   64   83   89  105  116  127  136  142  146  146    ...         0      0   \n",
       "51   109  117  125  131  142  151  156  159  165  170    ...         0      0   \n",
       "156   89  103  143  166  176  181  186  197  203  212    ...         0      0   \n",
       "146   87  115  123  129  146  149  157  163  154  159    ...         0      0   \n",
       "64    47   83  105  120  136  143  153  165  171  173    ...         0      0   \n",
       "3     20   22   47   83   91   98  111  116  121  121    ...         0      0   \n",
       "27   107  118  136  168  185  202  220  225  228  230    ...         0      0   \n",
       "12    64   98  127  140  147  153  169  178  181  188    ...         0      0   \n",
       "215   73   75   78  102  111   99   95   92  101  113    ...         0      0   \n",
       "144   20   25   50   80   89   99  120  112  130  138    ...         0      0   \n",
       "118  137  142  148  148  150  150  160  176  181  181    ...         0      0   \n",
       "73    64   94  108  119  139  144  151  164  171  179    ...         0      0   \n",
       "93     8    8   15   15   22   58   89  112  135  142    ...         0      0   \n",
       "99    73   83  100  117  136  146  163  172  180  181    ...         0      0   \n",
       "60   146  149  158  172  180  184  185  182  181  182    ...         0      0   \n",
       "170   81   92  100  112  117  150  174  181  182  179    ...         0      0   \n",
       "112   85   83   69   47   29   43   55   43   64   89    ...         0      0   \n",
       "134  104  113  121  123  131  137  149  154  154  144    ...         0      0   \n",
       "135   86  104  121  133  142  148  157  165  176  178    ...         0      0   \n",
       "\n",
       "     X4194  X4195  X4196  X4197  X4198  X4199  X4200         y  \n",
       "32       0      0      0      0      0      0      0       joy  \n",
       "56       0      0      0      0      0      0      0  surprise  \n",
       "17       0      0      0      0      0      0      0     anger  \n",
       "147      0      0      0      0      0      0      0      fear  \n",
       "140      0      0      0      0      0      0      0       joy  \n",
       "188      0      0      0      0      0      0      0   sadness  \n",
       "132      0      0      0      0      0      0      0   sadness  \n",
       "20       0      0      0      0      0      0      0   sadness  \n",
       "28       0      0      0      0      0      0      0       joy  \n",
       "155      0      0      0      0      0      0      0   disgust  \n",
       "46       0      0      0      0      0      0      0   disgust  \n",
       "100      0      0      0      0      0      0      0   disgust  \n",
       "10       0      0      0      0      0      0      0     anger  \n",
       "29       0      0      0      0      0      0      0       joy  \n",
       "14       0      0      0      0      0      0      0     anger  \n",
       "174      0      0      0      0      0      0      0     anger  \n",
       "82       0      0      0      0      0      0      0       joy  \n",
       "75       0      0      0      0      0      0      0   sadness  \n",
       "88       0      0      0      0      0      0      0       joy  \n",
       "178      0      0      0      0      0      0      0     anger  \n",
       "69       0      0      0      0      0      0      0     anger  \n",
       "66       0      0      0      0      0      0      0     anger  \n",
       "127      0      0      0      0      0      0      0   sadness  \n",
       "157      0      0      0      0      0      0      0   disgust  \n",
       "97       0      0      0      0      0      0      0      fear  \n",
       "109      0      0      0      0      0      0      0  surprise  \n",
       "152      0      0      0      0      0      0      0      fear  \n",
       "78       0      0      0      0      0      0      0   sadness  \n",
       "204      0      0      0      0      0      0      0      fear  \n",
       "59       0      0      0      0      0      0      0  surprise  \n",
       "..     ...    ...    ...    ...    ...    ...    ...       ...  \n",
       "67       0      0      0      0      0      0      0     anger  \n",
       "5        0      0      0      0      0      0      0  surprise  \n",
       "165      0      0      0      0      0      0      0  surprise  \n",
       "63       0      0      0      0      0      0      0  surprise  \n",
       "87       0      0      0      0      0      0      0       joy  \n",
       "104      0      0      0      0      0      0      0   disgust  \n",
       "89       0      0      0      0      0      0      0       joy  \n",
       "103      0      0      0      0      0      0      0   disgust  \n",
       "131      0      0      0      0      0      0      0   sadness  \n",
       "149      0      0      0      0      0      0      0      fear  \n",
       "72       0      0      0      0      0      0      0     anger  \n",
       "211      0      0      0      0      0      0      0   disgust  \n",
       "51       0      0      0      0      0      0      0   disgust  \n",
       "156      0      0      0      0      0      0      0   disgust  \n",
       "146      0      0      0      0      0      0      0      fear  \n",
       "64       0      0      0      0      0      0      0     anger  \n",
       "3        0      0      0      0      0      0      0  surprise  \n",
       "27       0      0      0      0      0      0      0   sadness  \n",
       "12       0      0      0      0      0      0      0     anger  \n",
       "215      0      0      0      0      0      0      0   disgust  \n",
       "144      0      0      0      0      0      0      0       joy  \n",
       "118      0      0      0      0      0      0      0     anger  \n",
       "73       0      0      0      0      0      0      0   sadness  \n",
       "93       0      0      0      0      0      0      0      fear  \n",
       "99       0      0      0      0      0      0      0      fear  \n",
       "60       0      0      0      0      0      0      0  surprise  \n",
       "170      0      0      0      0      0      0      0  surprise  \n",
       "112      0      0      0      0      0      0      0  surprise  \n",
       "134      0      0      0      0      0      0      0   sadness  \n",
       "135      0      0      0      0      0      0      0   sadness  \n",
       "\n",
       "[108 rows x 4201 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_expressions.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_expressions, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('y', axis=1)\n",
    "X_test = test.drop('y', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['y']\n",
    "y_test = test['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jean-Baptiste/anaconda2/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "/Users/Jean-Baptiste/anaconda2/lib/python2.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7ddfde42f189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtpot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTPOTClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Jean-Baptiste/anaconda2/lib/python2.7/site-packages/tpot/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    660\u001b[0m                     \u001b[0;31m# raise the exception if it's our last attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=13, population_size=13, verbosity=2)\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_fitted_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-babbcb6f645c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_fitted_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_fitted_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "_fitted_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surprise', 'joy', 'joy', 'anger', 'anger', 'sadness', 'surprise',\n",
       "       'disgust', 'disgust', 'fear', 'joy', 'sadness', 'anger', 'fear',\n",
       "       'sadness', 'sadness', 'fear', 'anger', 'surprise', 'joy', 'sadness',\n",
       "       'fear', 'sadness', 'joy', 'surprise', 'surprise', 'fear'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surprise', 'joy', 'joy', 'anger', 'anger', 'sadness', 'surprise',\n",
       "       'anger', 'disgust', 'fear', 'joy', 'sadness', 'anger', 'anger',\n",
       "       'sadness', 'sadness', 'fear', 'anger', 'fear', 'joy', 'sadness',\n",
       "       'fear', 'sadness', 'fear', 'surprise', 'surprise', 'fear'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: fear",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-200c42e1b9c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Jean-Baptiste/anaconda2/lib/python2.7/site-packages/tpot/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, testing_features, testing_target)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitted_pipeline_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0mtesting_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0mtesting_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         )\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: fear"
     ]
    }
   ],
   "source": [
    "tpot.score(X_test, np.asarray(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
