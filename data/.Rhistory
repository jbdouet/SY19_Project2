################################################################################################
#########################################CHARACTER##############################################
################################################################################################
################################################################################################
library(caret)
library("e1071")
library(randomForest)
character <- read.csv("characters_train.txt", sep =" ")
n=nrow(character)
ntrain=ceiling(n*2/3)
ntst=n-ntrain
train<-sample(1:n,ntrain)
character.test<-character[-train,]
character.train<-character[train,]
#Naive Bayes + double CV
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = ntrain)) # !!! le ntrain doit correspondre Ã  la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le mÃªme nombre d'Ã©lÃ©ments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
test_i <- which(folds_i == k)
# les datasets entre le fit et le predict doivent Ãªtre les mÃªmes car c'est le mÃªme dataset que l'on divise en k-fold
# on peut utiliser le data set complet ou seulement le train et avoir une idÃ©e finale de la performance sur le test
train_xy <- character.train[-test_i, ]
test_xy <- character.train[test_i, ]
print(k)
model_naive_bayes <- train(train_xy[,-1],train_xy$Y,method='nb',trControl= trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_naive_bayes<-predict.train(object=model_naive_bayes,test_xy[,-1])
cf<-confusionMatrix(test_xy$Y,predictions_naive_bayes)
CV[k]<- cf$overall["Accuracy"]
}
CVerror= sum(CV)/length(CV)
CV
CVerror#0.69
character.test<-character[-train,]
n=nrow(character)
ntrain=ceiling(n*2/3)
ntst=n-ntrain
train<-sample(1:n,ntrain)
character <- read.csv("characters_train.txt", sep =" ")
setwd("~/SY19/SY19_Project2/data")
character <- read.csv("characters_train.txt", sep =" ")
n=nrow(character)
ntrain=ceiling(n*2/3)
ntst=n-ntrain
train<-sample(1:n,ntrain)
character.test<-character[-train,]
character.train<-character[train,]
#Naive Bayes + double CV
n_folds <- 10
folds_i <- sample(rep(1:n_folds, length.out = ntrain)) # !!! le ntrain doit correspondre Ã  la taille du dataset que l'on utilisera dans la boucle de cross validation
table(folds_i) # Pas le mÃªme nombre d'Ã©lÃ©ments
CV<-rep(0,10)
for (k in 1:n_folds) {# we loop on the number of folds, to build k models
test_i <- which(folds_i == k)
# les datasets entre le fit et le predict doivent Ãªtre les mÃªmes car c'est le mÃªme dataset que l'on divise en k-fold
# on peut utiliser le data set complet ou seulement le train et avoir une idÃ©e finale de la performance sur le test
train_xy <- character.train[-test_i, ]
test_xy <- character.train[test_i, ]
print(k)
model_naive_bayes <- train(train_xy[,-1],train_xy$Y,method='nb',trControl= trainControl(
method = "cv",
number =10,
verboseIter = TRUE))
predictions_naive_bayes<-predict.train(object=model_naive_bayes,test_xy[,-1])
cf<-confusionMatrix(test_xy$Y,predictions_naive_bayes)
CV[k]<- cf$overall["Accuracy"]
}
install.packages('ORFridge')
library("ORFridge")
library(ORFridge)
library('ORFridge')
install.packages('ORFridge')
